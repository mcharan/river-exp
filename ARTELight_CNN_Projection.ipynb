{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "997688a5-c6a9-4a04-ab36-6f464e5089f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import collections\n",
    "import statistics\n",
    "import time\n",
    "import csv\n",
    "import os\n",
    "import sys\n",
    "import argparse\n",
    "import psutil\n",
    "from river import base, stats, utils, drift, metrics, preprocessing, datasets\n",
    "from river.datasets import synth\n",
    "from deep_river import classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7de35ea-8e88-4f90-a51c-520ef4da6e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. FUNÇÕES DE SUPORTE ---\n",
    "def generate_rotation_matrix(n_features):\n",
    "    random_matrix = torch.randn(n_features, n_features)\n",
    "    q, _ = torch.linalg.qr(random_matrix)\n",
    "    return q\n",
    "\n",
    "def log_results_to_csv(filename, data_dict):\n",
    "    file_exists = os.path.isfile(filename)\n",
    "    with open(filename, mode='a', newline='') as f:\n",
    "        writer = csv.DictWriter(f, fieldnames=data_dict.keys())\n",
    "        if not file_exists:\n",
    "            writer.writeheader()\n",
    "        writer.writerow(data_dict)\n",
    "        \n",
    "def fast_preprocess(X_batch, oh_encoder, scaler, n_feat):\n",
    "    X_df = pd.DataFrame(X_batch)\n",
    "    \n",
    "    # 1. Separar Categóricas (OHE) apenas se existirem strings\n",
    "    cat_cols = X_df.select_dtypes(include=['object', 'category']).columns\n",
    "    num_cols = X_df.select_dtypes(include=[np.number]).columns\n",
    "    \n",
    "    if len(cat_cols) > 0:\n",
    "        oh_encoder.learn_many(X_df[cat_cols])\n",
    "        X_cat = oh_encoder.transform_many(X_df[cat_cols])\n",
    "        X_combined = pd.concat([X_df[num_cols], X_cat], axis=1)\n",
    "    else:\n",
    "        X_combined = X_df[num_cols]\n",
    "    \n",
    "    # 2. Solução para o erro 'complex': Cálculo Manual do Scaler\n",
    "    # O River StandardScaler acumula médias e variâncias. \n",
    "    # Para evitar o erro, usamos os valores acumulados mas tratamos a raiz quadrada.\n",
    "    \n",
    "    # Atualiza o scaler do river (para manter compatibilidade se precisar)\n",
    "    scaler.learn_many(X_combined)\n",
    "    \n",
    "    # Extrai médias e variâncias acumuladas\n",
    "    means = np.array([scaler.means.get(c, 0) for c in X_combined.columns])\n",
    "    # PROTEÇÃO: clip(0) garante que variâncias negativas virem zero antes da raiz\n",
    "    vars_ = np.array([scaler.vars.get(c, 0) for c in X_combined.columns])\n",
    "    stds = np.sqrt(np.maximum(vars_, 0)) \n",
    "    \n",
    "    # 3. Transformação Manual (NumPy Puro)\n",
    "    X_raw = X_combined.values.astype(np.float64)\n",
    "    X_sc = (X_raw - means) / (stds + 1e-8) # 1e-8 evita divisão por zero\n",
    "    \n",
    "    # 4. Padding Eficiente\n",
    "    batch_size = len(X_batch)\n",
    "    data_fix = np.zeros((batch_size, n_feat))\n",
    "    cols_to_copy = min(X_sc.shape[1], n_feat)\n",
    "    data_fix[:, :cols_to_copy] = X_sc[:, :cols_to_copy]\n",
    "    \n",
    "    # 5. Saída para Dicionário (Rápido)\n",
    "    feature_names = [f\"f{j}\" for j in range(n_feat)]\n",
    "    return [dict(zip(feature_names, row)) for row in data_fix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b59a1374-ccf4-4eae-ad25-f14753d17078",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2. CONFIGURAÇÃO DE DATASETS  ---\n",
    "def get_dataset(name, seed, n_classes=2):\n",
    "    \"\"\"Retorna o stream e as dimensões esperadas pós-encoding.\"\"\"\n",
    "    if name.lower() == 'elec2':\n",
    "        # Elec2 tem 8 features originais -> ~17 após OneHot das categorias\n",
    "        return datasets.Elec2(), 17, 2\n",
    "    elif name.lower() == 'agrawal':\n",
    "        return synth.Agrawal(seed=seed), 10, 2\n",
    "    elif name.lower() == 'sea':\n",
    "        return synth.SEA(seed=seed), 3, 2\n",
    "    elif name.lower() == 'sine':\n",
    "        return synth.Sine(seed=seed), 3, 2\n",
    "    elif name.lower() == 'hyperplane':\n",
    "        return synth.Hyperplane(seed=seed, n_features=10), 10, 2\n",
    "    elif name.lower() == 'randomtree':\n",
    "        # Usando os parâmetros específicos fornecidos\n",
    "        return synth.RandomTree(\n",
    "            seed_tree=seed, \n",
    "            seed_sample=seed, \n",
    "            n_classes=n_classes, \n",
    "            n_num_features=5, \n",
    "            n_cat_features=5\n",
    "        ), 15, n_classes # 5 num + 5 cat (que expandem no OHE)\n",
    "    else:\n",
    "        raise ValueError(f\"Dataset {name} não configurado.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bd1603c2-c169-4802-ba18-9dd13a65f640",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 3. CLASSE DAS REDES NEURAIS (Mix Heterogêneo) ---\n",
    "class FlexibleNeuralNetwork(nn.Module):\n",
    "    def __init__(self, n_features, n_classes, hidden_layers=[32], use_cnn=False, projection_matrix=None):\n",
    "        super().__init__()\n",
    "        self.n_features = n_features\n",
    "        self.use_cnn = use_cnn\n",
    "        if projection_matrix is not None:\n",
    "            self.register_buffer('projection', projection_matrix.to(torch.float32))\n",
    "        else:\n",
    "            self.projection = None\n",
    "        self.in_dim = (8 * n_features) if use_cnn else n_features\n",
    "        if use_cnn:\n",
    "            self.cnn_block = nn.Sequential(nn.Conv1d(1, 8, 3, padding=1), nn.ReLU(), nn.Flatten())\n",
    "        else:\n",
    "            self.cnn_block = None\n",
    "        layers = []\n",
    "        curr = self.in_dim\n",
    "        for h in hidden_layers:\n",
    "            layers.append(nn.Linear(curr, h))\n",
    "            layers.append(nn.ReLU())\n",
    "            curr = h\n",
    "        layers.append(nn.Linear(curr, n_classes))\n",
    "        self.mlp_head = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        if x.dim() == 1: x = x.unsqueeze(0)\n",
    "        x = x.to(torch.float32)\n",
    "        if x.shape[1] != self.n_features:\n",
    "            tmp = torch.zeros((x.shape[0], self.n_features), device=x.device)\n",
    "            tmp[:, :min(x.shape[1], self.n_features)] = x[:, :min(x.shape[1], self.n_features)]\n",
    "            x = tmp\n",
    "        if self.projection is not None: x = torch.matmul(x, self.projection)\n",
    "        if self.use_cnn: x = self.cnn_block(x.unsqueeze(1))\n",
    "        return self.mlp_head(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "268a5229-f553-455a-89a4-719c8377a0b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FlexibleNN(nn.Module):\n",
    "    def __init__(self, n_features, n_classes, hidden_layers=[10]):\n",
    "        super(FlexibleNN, self).__init__()\n",
    "        layers = []\n",
    "        in_dim = n_features\n",
    "        \n",
    "        for h_dim in hidden_layers:\n",
    "            layers.append(nn.Linear(in_dim, h_dim))\n",
    "            layers.append(nn.ReLU())\n",
    "            in_dim = h_dim\n",
    "            \n",
    "        layers.append(nn.Linear(in_dim, n_classes))\n",
    "        self.net = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3ba5c00a-ac94-4fa5-a7d6-98d430262875",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ARTELight(base.Ensemble, base.Classifier):\n",
    "    def __init__(self, models, drift_detector, lambda_val=10.0, seed=42):\n",
    "        super().__init__(models=models)\n",
    "        self.lambda_val = lambda_val\n",
    "        self._rng = np.random.RandomState(seed)\n",
    "        self.drift_detector = drift_detector\n",
    "        self._detectors = [drift_detector.clone() for _ in range(len(models))]\n",
    "        self._acc_windows = [utils.Rolling(stats.Mean(), window_size=100) for _ in range(len(models))]\n",
    "        self._total_drifts = 0\n",
    "\n",
    "    # def learn_one(self, x, y):\n",
    "    #     any_drift = False\n",
    "    #     for i, model in enumerate(self.models):\n",
    "    #         # Usamos inference_mode para a predição interna de monitoramento\n",
    "    #         with torch.inference_mode():\n",
    "    #             y_pred = model.predict_one(x)\n",
    "            \n",
    "    #         correct = (y == y_pred)\n",
    "    #         self._detectors[i].update(0 if correct else 1)\n",
    "    #         self._acc_windows[i].update(1 if correct else 0)\n",
    "            \n",
    "    #         if not correct:\n",
    "    #             k = self._rng.poisson(self.lambda_val)\n",
    "    #             if k > 0:\n",
    "    #                 # OTIMIZAÇÃO: Transfere para a GPU uma única vez em lote\n",
    "    #                 x_df = pd.DataFrame([x] * k)\n",
    "    #                 y_df = pd.Series([y] * k)\n",
    "    #                 model.learn_many(x_df, y_df)\n",
    "\n",
    "    #         if self._detectors[i].drift_detected:\n",
    "    #             self._total_drifts += 1\n",
    "    #             # Criamos um novo modelo limpo em vez de clonar o estado treinado\n",
    "    #             self.models[i] = model.clone() \n",
    "    #             self._detectors[i] = self.drift_detector.clone()\n",
    "    #             self._acc_windows[i] = utils.Rolling(stats.Mean(), window_size=100)\n",
    "    #             any_drift = True\n",
    "    #     return any_drift\n",
    "\n",
    "    def learn_one(self, x, y):\n",
    "        any_drift = False\n",
    "        for i, model in enumerate(self.models):\n",
    "            # Usar o predict_one do Classifier (já otimizado)\n",
    "            y_pred = model.predict_one(x)\n",
    "            \n",
    "            correct = (y == y_pred)\n",
    "            self._detectors[i].update(0 if correct else 1)\n",
    "            self._acc_windows[i].update(1 if correct else 0)\n",
    "            \n",
    "            if not correct:\n",
    "                k = self._rng.poisson(self.lambda_val)\n",
    "                if k > 0:\n",
    "                    # OTIMIZAÇÃO: Transfere para a GPU uma única vez em lote\n",
    "                    x_df = pd.DataFrame([x] * k)\n",
    "                    y_df = pd.Series([y] * k)\n",
    "                    model.learn_many(x_df, y_df)\n",
    "\n",
    "            if self._detectors[i].drift_detected:\n",
    "                self._total_drifts += 1\n",
    "                # IMPORTANTE: Re-instanciar limpa o estado que o clone/deepcopy mantém\n",
    "                self.models[i] = model.clone() \n",
    "                self._detectors[i] = self.drift_detector.clone()\n",
    "                self._acc_windows[i] = utils.Rolling(stats.Mean(), window_size=100)\n",
    "                any_drift = True\n",
    "        return any_drift\n",
    "\n",
    "    @torch.inference_mode()\n",
    "    def predict_proba_one(self, x):\n",
    "        accs = [w.get() for w in self._acc_windows]\n",
    "        avg = sum(accs)/len(accs) if accs else 0\n",
    "        idx = [i for i, a in enumerate(accs) if a >= avg] or range(len(self.models))\n",
    "        votes = collections.Counter()\n",
    "        for i in idx:\n",
    "            p = self.models[i].predict_proba_one(x)\n",
    "            for c, v in p.items(): votes[c] += v / len(idx)\n",
    "        return votes\n",
    "\n",
    "    @property\n",
    "    def total_drifts(self): \n",
    "        return self._total_drifts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "13f5c6e1-71a3-4e6d-a309-289a61b0bda1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- WRAPPER PARA DESBALANCEAMENTO (Replicando BinaryImbalancedGenerator.java) ---\n",
    "class ImbalancedStream:\n",
    "    def __init__(self, stream, ir=0.1, seed=42):\n",
    "        self.stream = stream\n",
    "        self.ir = ir # Ex: 0.05 para 5% de classe minoritária\n",
    "        self.rng = np.random.RandomState(seed)\n",
    "        self.iterator = iter(self.stream)\n",
    "\n",
    "    def __iter__(self):\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        # Decide qual classe queremos com base na probabilidade IR\n",
    "        target_class = 1 if self.rng.rand() < self.ir else 0\n",
    "        \n",
    "        # Consome o stream original até achar a classe desejada\n",
    "        while True:\n",
    "            try:\n",
    "                x, y = next(self.iterator)\n",
    "                y_val = int(y) if isinstance(y, (int, float, bool, np.bool_)) else int(y)\n",
    "                if y_val == target_class:\n",
    "                    return x, y_val\n",
    "            except StopIteration:\n",
    "                raise StopIteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f484ac44-dce9-4d20-b3b3-cd74f181c6d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 4. EXECUÇÃO DO EXPERIMENTO ---\n",
    "def main(dataset='elec2', ir=None, seed=123456789, exp_type='binary', \n",
    "         n_models=30, n_classes=2, batch_size=32, n_instances=100000, lambda_val=6):\n",
    "    \n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "    # 1. Obter Stream e Configuração (respeitando n_classes para sintéticos)\n",
    "    stream_raw, n_feat, ds_classes = get_dataset(dataset, seed, n_classes)\n",
    "    # Se o dataset real tiver número fixo de classes (como Elec2), usamos o do dataset\n",
    "    final_n_classes = ds_classes if dataset.lower() != 'randomtree' else n_classes\n",
    "    \n",
    "    # 2. Aplicar Wrapper de Desbalanceamento (Protocolo Alberto Cano)\n",
    "    # Se ir=None, o stream segue original (ex: Elec2)\n",
    "    if ir is not None:\n",
    "        print(f\"Aplicando Static Imbalance Ratio: {ir*100}%\")\n",
    "        stream = ImbalancedStream(stream_raw, ir=ir, seed=seed)\n",
    "    else:\n",
    "        stream = stream_raw\n",
    "\n",
    "    loss_f = nn.CrossEntropyLoss() # Definida uma única vez para todos\n",
    "    # Mix de Arquiteturas Heterogêneas\n",
    "    ensemble_list = []\n",
    "    torch.manual_seed(seed)\n",
    "    for i in range(n_models):\n",
    "        if i < n_models//3:\n",
    "            cfg = {\"cnn\": False, \"opt\": optim.SGD, \"lr\": 0.05, \"layers\": [128, 64], \"proj\": False}\n",
    "        elif i < 2*n_models//3:\n",
    "            cfg = {\"cnn\": True, \"opt\": optim.Adam, \"lr\": 0.01, \"layers\": [64], \"proj\": False}\n",
    "        else:\n",
    "            cfg = {\"cnn\": False, \"opt\": optim.Adam, \"lr\": 0.005, \"layers\": [256, 128], \"proj\": True}\n",
    "        \n",
    "        proj = torch.randn(n_feat, n_feat) if cfg[\"proj\"] else None\n",
    "        if proj is not None: proj, _ = torch.linalg.qr(proj)\n",
    "\n",
    "        m = classification.Classifier(\n",
    "            module=FlexibleNeuralNetwork(n_feat, final_n_classes, cfg[\"layers\"], cfg[\"cnn\"], proj),\n",
    "            loss_fn=loss_f, \n",
    "            optimizer_fn=cfg[\"opt\"], \n",
    "            lr=cfg[\"lr\"], \n",
    "            device=device, \n",
    "            is_feature_incremental=False\n",
    "        )\n",
    "        ensemble_list.append(m)\n",
    "\n",
    "    model_artelmb = ARTELight(ensemble_list, drift.ADWIN(delta=1e-3), lambda_val=lambda_val, seed=seed)\n",
    "    # model_artelmb = ARTELightMB(ensemble_list, drift.ADWIN(delta=0.002), lambda_val=1.0, batch_limit=32, seed=seed)\n",
    "    \n",
    "    # Métricas do Survey [cite: 415, 469]\n",
    "    metric_acc = metrics.Accuracy()\n",
    "    metric_kappa = metrics.CohenKappa()\n",
    "    metric_gmean = metrics.GeometricMean()\n",
    "    \n",
    "    oh_encoder = preprocessing.OneHotEncoder()\n",
    "    scaler = preprocessing.StandardScaler()\n",
    "    X_batch, y_batch, latencies = [], [], []\n",
    "    # Organização de arquivos seguindo o padrão do repositório\n",
    "    os.makedirs(f\"results/{exp_type}\", exist_ok=True)\n",
    "    # ir_str = f\"_ir{ir}\" if ir else \"\"\n",
    "    # output_file = f\"results/{exp_type}/{dataset}{ir_str}_s{seed}_m{n_models}.csv\"\n",
    "    ir_suffix = f\"_ir{str(ir).replace('.','')}\" if ir is not None else \"\"\n",
    "    output_file = f\"results/{exp_type}/{dataset}{ir_suffix}_lamb{lambda_val}_s{seed}_m{n_models}.csv\"\n",
    "    \n",
    "    print(f\"Executando: {dataset.upper()} | Tipo: {exp_type} | Seed: {seed} | N_Feat: {n_feat}\")\n",
    "\n",
    "    for count, (x, y) in enumerate(stream, 1):\n",
    "\n",
    "        # LIMITADOR DE INSTÂNCIAS\n",
    "        if n_instances is not None and count > n_instances:\n",
    "            print(f\"Alcançado o limite de {n_instances} instâncias. Finalizando...\")\n",
    "            break\n",
    "        \n",
    "        # Conversão de label (funciona para binário e multiclasse)\n",
    "        y_val = int(y) if isinstance(y, (int, float, bool)) else y\n",
    "        X_batch.append(x); y_batch.append(1 if y else 0)\n",
    "        \n",
    "        if len(X_batch) == batch_size:\n",
    "            start = time.perf_counter()\n",
    "\n",
    "            # Preprocessing\n",
    "\n",
    "            \n",
    "            # X_df = pd.DataFrame(X_batch)\n",
    "            # oh_encoder.learn_many(X_df)\n",
    "            # X_oh = oh_encoder.transform_many(X_df).astype(np.float64)\n",
    "            # if hasattr(X_oh, \"sparse\"): X_oh = X_oh.sparse.to_dense()\n",
    "            # scaler.learn_many(X_oh)\n",
    "            # X_sc = scaler.transform_many(X_oh)\n",
    "            \n",
    "            # # Padding dinâmico baseado no n_feat da configuração\n",
    "            # data_fix = np.zeros((batch_size, n_feat))\n",
    "            # cols = min(X_sc.shape[1], n_feat)\n",
    "            # data_fix[:, :cols] = X_sc.iloc[:, :cols].values\n",
    "            # X_dicts = pd.DataFrame(data_fix, columns=[f\"f{j}\" for j in range(n_feat)]).to_dict(orient='records')\n",
    "            \n",
    "            X_dicts = fast_preprocess(X_batch, oh_encoder, scaler, n_feat)\n",
    "            \n",
    "            dur_prep = (time.perf_counter() - start)\n",
    "            \n",
    "            # Test-then-Train\n",
    "            any_drift = False\n",
    "            for i in range(batch_size):\n",
    "                t_pred = time.perf_counter()\n",
    "                y_pred = model_artelmb.predict_one(X_dicts[i])\n",
    "                dur_pred = (time.perf_counter() - t_pred)\n",
    "                \n",
    "                if y_pred is not None:\n",
    "                    metric_acc.update(y_batch[i], y_pred)\n",
    "                    metric_kappa.update(y_batch[i], y_pred)\n",
    "                    metric_gmean.update(y_batch[i], y_pred)\n",
    "                t_learn = time.perf_counter()\n",
    "                model_artelmb.learn_one(X_dicts[i], y_batch[i])\n",
    "                dur_learn = (time.perf_counter() - t_learn)\n",
    "                    \n",
    "\n",
    "            latencies.append((time.perf_counter() - start) * 1000)\n",
    "            X_batch, y_batch = [], []\n",
    "\n",
    "            if count % 2000 < batch_size:\n",
    "                import gc\n",
    "                gc.collect()\n",
    "                if torch.cuda.is_available():\n",
    "                    torch.cuda.empty_cache()\n",
    "                \n",
    "                ram = psutil.Process().memory_info().rss / (1024 * 1024)\n",
    "                vram = torch.cuda.memory_allocated() / (1024*1024) if torch.cuda.is_available() else 0\n",
    "                avg_lat = sum(latencies[-20:])/20 / batch_size\n",
    "                \n",
    "                stats_dict = {\n",
    "                    \"Instancia\": count, \n",
    "                    \"Dataset\": dataset, \n",
    "                    \"Seed\": seed,\n",
    "                    \"Accuracy\": metric_acc.get(), \n",
    "                    \"Kappa\": metric_kappa.get(),\n",
    "                    \"GMean\": metric_gmean.get(),\n",
    "                    \"Latencia_ms\": avg_lat, \n",
    "                    \"Drifts\": model_artelmb.total_drifts,\n",
    "                    \"RAM_MB\": ram, \n",
    "                    \"VRAM_MB\": vram,\n",
    "                    \"T_Prep\": dur_prep, \"T_Pred\": dur_pred, \"T_Learn\": dur_learn\n",
    "                }\n",
    "                log_results_to_csv(output_file, stats_dict)\n",
    "                print(f\"Inst: {count} | Acc: {stats_dict['Accuracy']:.2%} | Kappa: {stats_dict['Kappa']:.2f} | Drifts: {stats_dict['Drifts']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b5eb6789-69c8-4f22-a601-c6e5f0b2ebc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_static_imbalance_suite(datasets_list=['agrawal', 'sea'], seeds=[123456789], ir_list=[0.1, 0.05, 0.01]):\n",
    "    \"\"\"\n",
    "    Executa automaticamente os cenários de desbalanceamento estático.\n",
    "    ir=0.1  -> 10% classe minoritária (Moderado)\n",
    "    ir=0.05 -> 5%  classe minoritária (Severo)\n",
    "    ir=0.01 -> 1%  classe minoritária (Extremo)\n",
    "    \"\"\"\n",
    "    total_exps = len(datasets_list) * len(seeds) * len(ir_list)\n",
    "    curr = 1\n",
    "    \n",
    "    print(f\"Iniciando bateria de {total_exps} experimentos...\")\n",
    "    \n",
    "    for ds in datasets_list:\n",
    "        for seed in seeds:\n",
    "            for ir in ir_list:\n",
    "                print(f\"\\n[{curr}/{total_exps}] Processando: {ds} | IR: {ir*100}% | Seed: {seed}\")\n",
    "                try:\n",
    "                    main(\n",
    "                        dataset=ds,\n",
    "                        ir=ir,\n",
    "                        seed=seed,\n",
    "                        exp_type='static_ir',\n",
    "                        n_models=30,\n",
    "                        batch_size=32\n",
    "                    )\n",
    "                except Exception as e:\n",
    "                    print(f\"Erro no experimento {ds} IR {ir}: {e}\")\n",
    "                curr += 1\n",
    "    print(\"\\nBateria de testes concluída com sucesso!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "81c6b223-c3a1-4b8d-bffb-aa680e1365a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_full_experiment_suite():\n",
    "    # Configurações de Datasets Sintéticos (Protocolo Cano)\n",
    "    sinteticos = ['agrawal', 'sea']\n",
    "    lambdas = [6, 10]\n",
    "    irs = [0.1, 0.01] # 10% e 1%\n",
    "    seeds = [123456789]\n",
    "    n_inst = 100000 # 100k é o padrão para estabilidade\n",
    "    \n",
    "    print(\"Iniciando Suíte de Experimentos Otimizada\")\n",
    "\n",
    "    for ds in sinteticos:\n",
    "        for lamb in lambdas:\n",
    "            for ir in irs:\n",
    "                for s in seeds:\n",
    "                    print(f\"\\n# Executando: {ds} | IR: {ir} | Lambda: {lamb} | Seed: {s}\")\n",
    "                    main(\n",
    "                        dataset=ds,\n",
    "                        ir=ir,\n",
    "                        seed=s,\n",
    "                        exp_type='static_ir',\n",
    "                        n_models=30,\n",
    "                        batch_size=32,\n",
    "                        n_instances=n_inst,\n",
    "                        lambda_val=lamb\n",
    "                    )\n",
    "\n",
    "    # Execução do Elec2 (Real) - Lambda 6 e 10 para comparação\n",
    "    print(\"\\n# Executando Dataset Real: Elec2\")\n",
    "    for lamb in lambdas:\n",
    "        main(\n",
    "            dataset='elec2',\n",
    "            seed=123456789,\n",
    "            exp_type='binary',\n",
    "            n_models=30,\n",
    "            batch_size=32,\n",
    "            n_instances=None, # Roda o arquivo todo (45k)\n",
    "            lambda_val=lamb\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fc69662c-3b9d-44f7-b595-89b66812f5b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ambiente Notebook detectado. Usando parâmetros padrão...\n",
      "Iniciando Suíte de Experimentos Otimizada\n",
      "\n",
      "# Executando: agrawal | IR: 0.1 | Lambda: 6 | Seed: 123456789\n",
      "Aplicando Static Imbalance Ratio: 10.0%\n",
      "Executando: AGRAWAL | Tipo: static_ir | Seed: 123456789 | N_Feat: 10\n",
      "Inst: 2016 | Acc: 96.18% | Kappa: 0.76 | Drifts: 1\n",
      "Inst: 4000 | Acc: 96.28% | Kappa: 0.77 | Drifts: 19\n",
      "Inst: 6016 | Acc: 96.78% | Kappa: 0.80 | Drifts: 38\n",
      "Inst: 8000 | Acc: 96.67% | Kappa: 0.79 | Drifts: 58\n",
      "Inst: 10016 | Acc: 96.60% | Kappa: 0.78 | Drifts: 81\n",
      "Inst: 12000 | Acc: 96.55% | Kappa: 0.78 | Drifts: 95\n",
      "Inst: 14016 | Acc: 96.53% | Kappa: 0.78 | Drifts: 110\n",
      "Inst: 16000 | Acc: 96.51% | Kappa: 0.78 | Drifts: 133\n",
      "Inst: 18016 | Acc: 96.44% | Kappa: 0.77 | Drifts: 158\n",
      "Inst: 20000 | Acc: 96.37% | Kappa: 0.77 | Drifts: 184\n",
      "Inst: 22016 | Acc: 96.31% | Kappa: 0.77 | Drifts: 201\n",
      "Inst: 24000 | Acc: 96.17% | Kappa: 0.76 | Drifts: 221\n",
      "Inst: 26016 | Acc: 96.13% | Kappa: 0.76 | Drifts: 239\n",
      "Inst: 28000 | Acc: 96.13% | Kappa: 0.75 | Drifts: 263\n",
      "Inst: 30016 | Acc: 96.02% | Kappa: 0.74 | Drifts: 282\n",
      "Inst: 32000 | Acc: 95.98% | Kappa: 0.74 | Drifts: 298\n",
      "Inst: 34016 | Acc: 95.94% | Kappa: 0.74 | Drifts: 312\n",
      "Inst: 36000 | Acc: 95.93% | Kappa: 0.74 | Drifts: 335\n",
      "Inst: 38016 | Acc: 95.96% | Kappa: 0.74 | Drifts: 347\n",
      "Inst: 40000 | Acc: 95.92% | Kappa: 0.74 | Drifts: 361\n",
      "Inst: 42016 | Acc: 95.94% | Kappa: 0.74 | Drifts: 373\n",
      "Inst: 44000 | Acc: 95.96% | Kappa: 0.74 | Drifts: 389\n",
      "Inst: 46016 | Acc: 96.01% | Kappa: 0.75 | Drifts: 404\n",
      "Inst: 48000 | Acc: 96.01% | Kappa: 0.75 | Drifts: 419\n",
      "Inst: 50016 | Acc: 95.97% | Kappa: 0.74 | Drifts: 435\n",
      "Inst: 52000 | Acc: 95.97% | Kappa: 0.74 | Drifts: 447\n",
      "Inst: 54016 | Acc: 95.98% | Kappa: 0.74 | Drifts: 456\n",
      "Inst: 56000 | Acc: 95.99% | Kappa: 0.74 | Drifts: 466\n",
      "Inst: 58016 | Acc: 95.97% | Kappa: 0.74 | Drifts: 479\n",
      "Inst: 60000 | Acc: 95.95% | Kappa: 0.74 | Drifts: 487\n",
      "Inst: 62016 | Acc: 95.96% | Kappa: 0.74 | Drifts: 497\n",
      "Inst: 64000 | Acc: 95.95% | Kappa: 0.74 | Drifts: 502\n",
      "Inst: 66016 | Acc: 95.94% | Kappa: 0.74 | Drifts: 512\n",
      "Inst: 68000 | Acc: 95.90% | Kappa: 0.74 | Drifts: 520\n",
      "Inst: 70016 | Acc: 95.88% | Kappa: 0.74 | Drifts: 529\n",
      "Inst: 72000 | Acc: 95.86% | Kappa: 0.74 | Drifts: 534\n",
      "Inst: 74016 | Acc: 95.83% | Kappa: 0.73 | Drifts: 538\n",
      "Inst: 76000 | Acc: 95.83% | Kappa: 0.73 | Drifts: 541\n",
      "Inst: 78016 | Acc: 95.78% | Kappa: 0.73 | Drifts: 546\n",
      "Inst: 80000 | Acc: 95.77% | Kappa: 0.73 | Drifts: 552\n",
      "Inst: 82016 | Acc: 95.73% | Kappa: 0.73 | Drifts: 561\n",
      "Inst: 84000 | Acc: 95.72% | Kappa: 0.72 | Drifts: 569\n",
      "Inst: 86016 | Acc: 95.73% | Kappa: 0.73 | Drifts: 578\n",
      "Inst: 88000 | Acc: 95.74% | Kappa: 0.73 | Drifts: 586\n",
      "Inst: 90016 | Acc: 95.76% | Kappa: 0.73 | Drifts: 591\n",
      "Inst: 92000 | Acc: 95.74% | Kappa: 0.73 | Drifts: 599\n",
      "Inst: 94016 | Acc: 95.73% | Kappa: 0.73 | Drifts: 606\n",
      "Inst: 96000 | Acc: 95.71% | Kappa: 0.72 | Drifts: 615\n",
      "Inst: 98016 | Acc: 95.69% | Kappa: 0.72 | Drifts: 624\n",
      "Inst: 100000 | Acc: 95.67% | Kappa: 0.72 | Drifts: 629\n",
      "Alcançado o limite de 100000 instâncias. Finalizando...\n",
      "\n",
      "# Executando: agrawal | IR: 0.01 | Lambda: 6 | Seed: 123456789\n",
      "Aplicando Static Imbalance Ratio: 1.0%\n",
      "Executando: AGRAWAL | Tipo: static_ir | Seed: 123456789 | N_Feat: 10\n",
      "Inst: 2016 | Acc: 99.01% | Kappa: 0.37 | Drifts: 0\n",
      "Inst: 4000 | Acc: 99.33% | Kappa: 0.55 | Drifts: 0\n",
      "Inst: 6016 | Acc: 99.45% | Kappa: 0.67 | Drifts: 0\n",
      "Inst: 8000 | Acc: 99.56% | Kappa: 0.73 | Drifts: 0\n",
      "Inst: 10016 | Acc: 99.55% | Kappa: 0.72 | Drifts: 7\n",
      "Inst: 12000 | Acc: 99.58% | Kappa: 0.74 | Drifts: 8\n",
      "Inst: 14016 | Acc: 99.58% | Kappa: 0.76 | Drifts: 18\n",
      "Inst: 16000 | Acc: 99.59% | Kappa: 0.77 | Drifts: 19\n",
      "Inst: 18016 | Acc: 99.62% | Kappa: 0.78 | Drifts: 20\n",
      "Inst: 20000 | Acc: 99.61% | Kappa: 0.79 | Drifts: 27\n",
      "Inst: 22016 | Acc: 99.62% | Kappa: 0.79 | Drifts: 38\n",
      "Inst: 24000 | Acc: 99.64% | Kappa: 0.80 | Drifts: 43\n",
      "Inst: 26016 | Acc: 99.64% | Kappa: 0.80 | Drifts: 49\n",
      "Inst: 28000 | Acc: 99.64% | Kappa: 0.79 | Drifts: 51\n",
      "Inst: 30016 | Acc: 99.64% | Kappa: 0.80 | Drifts: 60\n",
      "Inst: 32000 | Acc: 99.63% | Kappa: 0.80 | Drifts: 65\n",
      "Inst: 34016 | Acc: 99.63% | Kappa: 0.80 | Drifts: 67\n",
      "Inst: 36000 | Acc: 99.64% | Kappa: 0.81 | Drifts: 70\n",
      "Inst: 38016 | Acc: 99.64% | Kappa: 0.81 | Drifts: 72\n",
      "Inst: 40000 | Acc: 99.65% | Kappa: 0.81 | Drifts: 73\n",
      "Inst: 42016 | Acc: 99.65% | Kappa: 0.81 | Drifts: 76\n",
      "Inst: 44000 | Acc: 99.65% | Kappa: 0.81 | Drifts: 85\n",
      "Inst: 46016 | Acc: 99.65% | Kappa: 0.80 | Drifts: 91\n",
      "Inst: 48000 | Acc: 99.66% | Kappa: 0.81 | Drifts: 93\n",
      "Inst: 50016 | Acc: 99.65% | Kappa: 0.80 | Drifts: 93\n",
      "Inst: 52000 | Acc: 99.66% | Kappa: 0.81 | Drifts: 95\n",
      "Inst: 54016 | Acc: 99.66% | Kappa: 0.81 | Drifts: 101\n",
      "Inst: 56000 | Acc: 99.66% | Kappa: 0.81 | Drifts: 101\n",
      "Inst: 58016 | Acc: 99.66% | Kappa: 0.81 | Drifts: 101\n",
      "Inst: 60000 | Acc: 99.66% | Kappa: 0.81 | Drifts: 103\n",
      "Inst: 62016 | Acc: 99.66% | Kappa: 0.81 | Drifts: 109\n",
      "Inst: 64000 | Acc: 99.67% | Kappa: 0.81 | Drifts: 111\n",
      "Inst: 66016 | Acc: 99.67% | Kappa: 0.81 | Drifts: 112\n",
      "Inst: 68000 | Acc: 99.67% | Kappa: 0.81 | Drifts: 115\n",
      "Inst: 70016 | Acc: 99.67% | Kappa: 0.81 | Drifts: 119\n",
      "Inst: 72000 | Acc: 99.67% | Kappa: 0.81 | Drifts: 124\n",
      "Inst: 74016 | Acc: 99.66% | Kappa: 0.81 | Drifts: 132\n",
      "Inst: 76000 | Acc: 99.66% | Kappa: 0.81 | Drifts: 134\n",
      "Inst: 78016 | Acc: 99.66% | Kappa: 0.81 | Drifts: 136\n",
      "Inst: 80000 | Acc: 99.67% | Kappa: 0.81 | Drifts: 142\n",
      "Inst: 82016 | Acc: 99.66% | Kappa: 0.81 | Drifts: 144\n",
      "Inst: 84000 | Acc: 99.66% | Kappa: 0.81 | Drifts: 148\n",
      "Inst: 86016 | Acc: 99.66% | Kappa: 0.81 | Drifts: 149\n",
      "Inst: 88000 | Acc: 99.67% | Kappa: 0.81 | Drifts: 155\n",
      "Inst: 90016 | Acc: 99.66% | Kappa: 0.81 | Drifts: 159\n",
      "Inst: 92000 | Acc: 99.66% | Kappa: 0.81 | Drifts: 167\n",
      "Inst: 94016 | Acc: 99.66% | Kappa: 0.81 | Drifts: 169\n",
      "Inst: 96000 | Acc: 99.66% | Kappa: 0.81 | Drifts: 169\n",
      "Inst: 98016 | Acc: 99.66% | Kappa: 0.81 | Drifts: 170\n",
      "Inst: 100000 | Acc: 99.66% | Kappa: 0.81 | Drifts: 175\n",
      "Alcançado o limite de 100000 instâncias. Finalizando...\n",
      "\n",
      "# Executando: agrawal | IR: 0.1 | Lambda: 10 | Seed: 123456789\n",
      "Aplicando Static Imbalance Ratio: 10.0%\n",
      "Executando: AGRAWAL | Tipo: static_ir | Seed: 123456789 | N_Feat: 10\n",
      "Inst: 2016 | Acc: 95.14% | Kappa: 0.71 | Drifts: 0\n",
      "Inst: 4000 | Acc: 95.67% | Kappa: 0.74 | Drifts: 20\n",
      "Inst: 6016 | Acc: 96.08% | Kappa: 0.76 | Drifts: 39\n",
      "Inst: 8000 | Acc: 95.76% | Kappa: 0.74 | Drifts: 49\n",
      "Inst: 10016 | Acc: 95.56% | Kappa: 0.73 | Drifts: 58\n",
      "Inst: 12000 | Acc: 95.47% | Kappa: 0.73 | Drifts: 67\n",
      "Inst: 14016 | Acc: 95.26% | Kappa: 0.72 | Drifts: 86\n",
      "Inst: 16000 | Acc: 95.26% | Kappa: 0.72 | Drifts: 105\n",
      "Inst: 18016 | Acc: 95.16% | Kappa: 0.71 | Drifts: 143\n",
      "Inst: 20000 | Acc: 95.14% | Kappa: 0.71 | Drifts: 183\n",
      "Inst: 22016 | Acc: 95.09% | Kappa: 0.71 | Drifts: 202\n",
      "Inst: 24000 | Acc: 95.07% | Kappa: 0.71 | Drifts: 251\n",
      "Inst: 26016 | Acc: 95.04% | Kappa: 0.71 | Drifts: 272\n",
      "Inst: 28000 | Acc: 95.01% | Kappa: 0.70 | Drifts: 321\n",
      "Inst: 30016 | Acc: 94.85% | Kappa: 0.69 | Drifts: 341\n",
      "Inst: 32000 | Acc: 94.69% | Kappa: 0.68 | Drifts: 361\n",
      "Inst: 34016 | Acc: 94.66% | Kappa: 0.67 | Drifts: 381\n",
      "Inst: 36000 | Acc: 94.69% | Kappa: 0.68 | Drifts: 410\n",
      "Inst: 38016 | Acc: 94.58% | Kappa: 0.67 | Drifts: 431\n",
      "Inst: 40000 | Acc: 94.55% | Kappa: 0.67 | Drifts: 441\n",
      "Inst: 42016 | Acc: 94.53% | Kappa: 0.67 | Drifts: 460\n",
      "Inst: 44000 | Acc: 94.46% | Kappa: 0.66 | Drifts: 480\n",
      "Inst: 46016 | Acc: 94.43% | Kappa: 0.66 | Drifts: 480\n",
      "Inst: 48000 | Acc: 94.46% | Kappa: 0.66 | Drifts: 481\n",
      "Inst: 50016 | Acc: 94.46% | Kappa: 0.67 | Drifts: 490\n",
      "Inst: 52000 | Acc: 94.55% | Kappa: 0.67 | Drifts: 499\n",
      "Inst: 54016 | Acc: 94.55% | Kappa: 0.67 | Drifts: 509\n",
      "Inst: 56000 | Acc: 94.45% | Kappa: 0.66 | Drifts: 531\n",
      "Inst: 58016 | Acc: 94.46% | Kappa: 0.67 | Drifts: 541\n",
      "Inst: 60000 | Acc: 94.44% | Kappa: 0.66 | Drifts: 551\n",
      "Inst: 62016 | Acc: 94.43% | Kappa: 0.66 | Drifts: 561\n",
      "Inst: 64000 | Acc: 94.41% | Kappa: 0.66 | Drifts: 571\n",
      "Inst: 66016 | Acc: 94.35% | Kappa: 0.66 | Drifts: 591\n",
      "Inst: 68000 | Acc: 94.29% | Kappa: 0.65 | Drifts: 601\n",
      "Inst: 70016 | Acc: 94.22% | Kappa: 0.65 | Drifts: 611\n",
      "Inst: 72000 | Acc: 94.16% | Kappa: 0.64 | Drifts: 621\n",
      "Inst: 74016 | Acc: 94.16% | Kappa: 0.64 | Drifts: 631\n",
      "Inst: 76000 | Acc: 94.10% | Kappa: 0.64 | Drifts: 641\n",
      "Inst: 78016 | Acc: 94.09% | Kappa: 0.64 | Drifts: 651\n",
      "Inst: 80000 | Acc: 94.07% | Kappa: 0.64 | Drifts: 678\n",
      "Inst: 82016 | Acc: 94.03% | Kappa: 0.63 | Drifts: 687\n",
      "Inst: 84000 | Acc: 94.05% | Kappa: 0.64 | Drifts: 696\n",
      "Inst: 86016 | Acc: 94.05% | Kappa: 0.64 | Drifts: 714\n",
      "Inst: 88000 | Acc: 94.03% | Kappa: 0.63 | Drifts: 724\n",
      "Inst: 90016 | Acc: 94.04% | Kappa: 0.63 | Drifts: 733\n",
      "Inst: 92000 | Acc: 94.06% | Kappa: 0.64 | Drifts: 734\n",
      "Inst: 94016 | Acc: 94.04% | Kappa: 0.63 | Drifts: 737\n",
      "Inst: 96000 | Acc: 94.00% | Kappa: 0.63 | Drifts: 740\n",
      "Inst: 98016 | Acc: 93.99% | Kappa: 0.63 | Drifts: 743\n",
      "Inst: 100000 | Acc: 94.00% | Kappa: 0.63 | Drifts: 746\n",
      "Alcançado o limite de 100000 instâncias. Finalizando...\n",
      "\n",
      "# Executando: agrawal | IR: 0.01 | Lambda: 10 | Seed: 123456789\n",
      "Aplicando Static Imbalance Ratio: 1.0%\n",
      "Executando: AGRAWAL | Tipo: static_ir | Seed: 123456789 | N_Feat: 10\n",
      "Inst: 2016 | Acc: 98.96% | Kappa: 0.36 | Drifts: 0\n",
      "Inst: 4000 | Acc: 99.33% | Kappa: 0.55 | Drifts: 0\n",
      "Inst: 6016 | Acc: 99.47% | Kappa: 0.68 | Drifts: 0\n",
      "Inst: 8000 | Acc: 99.58% | Kappa: 0.74 | Drifts: 0\n",
      "Inst: 10016 | Acc: 99.54% | Kappa: 0.72 | Drifts: 10\n",
      "Inst: 12000 | Acc: 99.56% | Kappa: 0.73 | Drifts: 10\n",
      "Inst: 14016 | Acc: 99.57% | Kappa: 0.75 | Drifts: 21\n",
      "Inst: 16000 | Acc: 99.58% | Kappa: 0.77 | Drifts: 21\n",
      "Inst: 18016 | Acc: 99.61% | Kappa: 0.78 | Drifts: 21\n",
      "Inst: 20000 | Acc: 99.61% | Kappa: 0.79 | Drifts: 31\n",
      "Inst: 22016 | Acc: 99.58% | Kappa: 0.77 | Drifts: 41\n",
      "Inst: 24000 | Acc: 99.59% | Kappa: 0.78 | Drifts: 42\n",
      "Inst: 26016 | Acc: 99.60% | Kappa: 0.78 | Drifts: 51\n",
      "Inst: 28000 | Acc: 99.60% | Kappa: 0.78 | Drifts: 51\n",
      "Inst: 30016 | Acc: 99.60% | Kappa: 0.78 | Drifts: 61\n",
      "Inst: 32000 | Acc: 99.57% | Kappa: 0.77 | Drifts: 71\n",
      "Inst: 34016 | Acc: 99.57% | Kappa: 0.77 | Drifts: 71\n",
      "Inst: 36000 | Acc: 99.58% | Kappa: 0.78 | Drifts: 81\n",
      "Inst: 38016 | Acc: 99.58% | Kappa: 0.78 | Drifts: 81\n",
      "Inst: 40000 | Acc: 99.59% | Kappa: 0.78 | Drifts: 81\n",
      "Inst: 42016 | Acc: 99.59% | Kappa: 0.78 | Drifts: 81\n",
      "Inst: 44000 | Acc: 99.60% | Kappa: 0.79 | Drifts: 91\n",
      "Inst: 46016 | Acc: 99.60% | Kappa: 0.78 | Drifts: 101\n",
      "Inst: 48000 | Acc: 99.60% | Kappa: 0.78 | Drifts: 101\n",
      "Inst: 50016 | Acc: 99.59% | Kappa: 0.77 | Drifts: 101\n",
      "Inst: 52000 | Acc: 99.60% | Kappa: 0.78 | Drifts: 101\n",
      "Inst: 54016 | Acc: 99.59% | Kappa: 0.78 | Drifts: 111\n",
      "Inst: 56000 | Acc: 99.60% | Kappa: 0.78 | Drifts: 111\n",
      "Inst: 58016 | Acc: 99.60% | Kappa: 0.78 | Drifts: 111\n",
      "Inst: 60000 | Acc: 99.60% | Kappa: 0.78 | Drifts: 111\n",
      "Inst: 62016 | Acc: 99.60% | Kappa: 0.78 | Drifts: 121\n",
      "Inst: 64000 | Acc: 99.60% | Kappa: 0.78 | Drifts: 121\n",
      "Inst: 66016 | Acc: 99.60% | Kappa: 0.78 | Drifts: 121\n",
      "Inst: 68000 | Acc: 99.61% | Kappa: 0.78 | Drifts: 121\n",
      "Inst: 70016 | Acc: 99.61% | Kappa: 0.79 | Drifts: 121\n",
      "Inst: 72000 | Acc: 99.61% | Kappa: 0.78 | Drifts: 131\n",
      "Inst: 74016 | Acc: 99.61% | Kappa: 0.78 | Drifts: 141\n",
      "Inst: 76000 | Acc: 99.61% | Kappa: 0.78 | Drifts: 141\n",
      "Inst: 78016 | Acc: 99.61% | Kappa: 0.78 | Drifts: 141\n",
      "Inst: 80000 | Acc: 99.61% | Kappa: 0.78 | Drifts: 150\n",
      "Inst: 82016 | Acc: 99.61% | Kappa: 0.78 | Drifts: 160\n",
      "Inst: 84000 | Acc: 99.61% | Kappa: 0.78 | Drifts: 160\n",
      "Inst: 86016 | Acc: 99.61% | Kappa: 0.78 | Drifts: 161\n",
      "Inst: 88000 | Acc: 99.61% | Kappa: 0.78 | Drifts: 161\n",
      "Inst: 90016 | Acc: 99.61% | Kappa: 0.78 | Drifts: 161\n",
      "Inst: 92000 | Acc: 99.61% | Kappa: 0.78 | Drifts: 181\n",
      "Inst: 94016 | Acc: 99.61% | Kappa: 0.78 | Drifts: 181\n",
      "Inst: 96000 | Acc: 99.60% | Kappa: 0.78 | Drifts: 181\n",
      "Inst: 98016 | Acc: 99.60% | Kappa: 0.78 | Drifts: 181\n",
      "Inst: 100000 | Acc: 99.60% | Kappa: 0.78 | Drifts: 190\n",
      "Alcançado o limite de 100000 instâncias. Finalizando...\n",
      "\n",
      "# Executando: sea | IR: 0.1 | Lambda: 6 | Seed: 123456789\n",
      "Aplicando Static Imbalance Ratio: 10.0%\n",
      "Executando: SEA | Tipo: static_ir | Seed: 123456789 | N_Feat: 3\n",
      "Inst: 2016 | Acc: 98.56% | Kappa: 0.91 | Drifts: 0\n",
      "Inst: 4000 | Acc: 98.95% | Kappa: 0.94 | Drifts: 0\n",
      "Inst: 6016 | Acc: 99.15% | Kappa: 0.95 | Drifts: 3\n",
      "Inst: 8000 | Acc: 99.25% | Kappa: 0.96 | Drifts: 4\n",
      "Inst: 10016 | Acc: 99.31% | Kappa: 0.96 | Drifts: 20\n",
      "Inst: 12000 | Acc: 99.32% | Kappa: 0.96 | Drifts: 25\n",
      "Inst: 14016 | Acc: 99.35% | Kappa: 0.96 | Drifts: 30\n",
      "Inst: 16000 | Acc: 99.34% | Kappa: 0.96 | Drifts: 38\n",
      "Inst: 18016 | Acc: 99.35% | Kappa: 0.96 | Drifts: 49\n",
      "Inst: 20000 | Acc: 99.36% | Kappa: 0.96 | Drifts: 58\n",
      "Inst: 22016 | Acc: 99.36% | Kappa: 0.96 | Drifts: 64\n",
      "Inst: 24000 | Acc: 99.38% | Kappa: 0.97 | Drifts: 71\n",
      "Inst: 26016 | Acc: 99.39% | Kappa: 0.97 | Drifts: 78\n",
      "Inst: 28000 | Acc: 99.40% | Kappa: 0.97 | Drifts: 85\n",
      "Inst: 30016 | Acc: 99.41% | Kappa: 0.97 | Drifts: 86\n",
      "Inst: 32000 | Acc: 99.42% | Kappa: 0.97 | Drifts: 98\n",
      "Inst: 34016 | Acc: 99.41% | Kappa: 0.97 | Drifts: 99\n",
      "Inst: 36000 | Acc: 99.41% | Kappa: 0.97 | Drifts: 99\n",
      "Inst: 38016 | Acc: 99.42% | Kappa: 0.97 | Drifts: 102\n",
      "Inst: 40000 | Acc: 99.43% | Kappa: 0.97 | Drifts: 105\n",
      "Inst: 42016 | Acc: 99.45% | Kappa: 0.97 | Drifts: 110\n",
      "Inst: 44000 | Acc: 99.45% | Kappa: 0.97 | Drifts: 114\n",
      "Inst: 46016 | Acc: 99.43% | Kappa: 0.97 | Drifts: 124\n",
      "Inst: 48000 | Acc: 99.43% | Kappa: 0.97 | Drifts: 128\n",
      "Inst: 50016 | Acc: 99.42% | Kappa: 0.97 | Drifts: 130\n",
      "Inst: 52000 | Acc: 99.42% | Kappa: 0.97 | Drifts: 130\n",
      "Inst: 54016 | Acc: 99.42% | Kappa: 0.97 | Drifts: 137\n",
      "Inst: 56000 | Acc: 99.41% | Kappa: 0.97 | Drifts: 148\n",
      "Inst: 58016 | Acc: 99.41% | Kappa: 0.97 | Drifts: 158\n",
      "Inst: 60000 | Acc: 99.41% | Kappa: 0.97 | Drifts: 161\n",
      "Inst: 62016 | Acc: 99.41% | Kappa: 0.97 | Drifts: 164\n",
      "Inst: 64000 | Acc: 99.41% | Kappa: 0.97 | Drifts: 167\n",
      "Inst: 66016 | Acc: 99.42% | Kappa: 0.97 | Drifts: 177\n",
      "Inst: 68000 | Acc: 99.41% | Kappa: 0.97 | Drifts: 187\n",
      "Inst: 70016 | Acc: 99.40% | Kappa: 0.97 | Drifts: 199\n",
      "Inst: 72000 | Acc: 99.40% | Kappa: 0.97 | Drifts: 204\n",
      "Inst: 74016 | Acc: 99.40% | Kappa: 0.97 | Drifts: 210\n",
      "Inst: 76000 | Acc: 99.40% | Kappa: 0.97 | Drifts: 212\n",
      "Inst: 78016 | Acc: 99.39% | Kappa: 0.97 | Drifts: 223\n",
      "Inst: 80000 | Acc: 99.39% | Kappa: 0.97 | Drifts: 228\n",
      "Inst: 82016 | Acc: 99.39% | Kappa: 0.97 | Drifts: 229\n",
      "Inst: 84000 | Acc: 99.39% | Kappa: 0.97 | Drifts: 234\n",
      "Inst: 86016 | Acc: 99.39% | Kappa: 0.97 | Drifts: 244\n",
      "Inst: 88000 | Acc: 99.39% | Kappa: 0.97 | Drifts: 247\n",
      "Inst: 90016 | Acc: 99.39% | Kappa: 0.97 | Drifts: 258\n",
      "Inst: 92000 | Acc: 99.39% | Kappa: 0.97 | Drifts: 261\n",
      "Inst: 94016 | Acc: 99.39% | Kappa: 0.97 | Drifts: 269\n",
      "Inst: 96000 | Acc: 99.40% | Kappa: 0.97 | Drifts: 273\n",
      "Inst: 98016 | Acc: 99.39% | Kappa: 0.97 | Drifts: 284\n",
      "Inst: 100000 | Acc: 99.39% | Kappa: 0.97 | Drifts: 288\n",
      "Alcançado o limite de 100000 instâncias. Finalizando...\n",
      "\n",
      "# Executando: sea | IR: 0.01 | Lambda: 6 | Seed: 123456789\n",
      "Aplicando Static Imbalance Ratio: 1.0%\n",
      "Executando: SEA | Tipo: static_ir | Seed: 123456789 | N_Feat: 3\n",
      "Inst: 2016 | Acc: 99.11% | Kappa: 0.47 | Drifts: 0\n",
      "Inst: 4000 | Acc: 99.40% | Kappa: 0.61 | Drifts: 0\n",
      "Inst: 6016 | Acc: 99.50% | Kappa: 0.70 | Drifts: 0\n",
      "Inst: 8000 | Acc: 99.55% | Kappa: 0.71 | Drifts: 0\n",
      "Inst: 10016 | Acc: 99.56% | Kappa: 0.73 | Drifts: 0\n",
      "Inst: 12000 | Acc: 99.61% | Kappa: 0.76 | Drifts: 9\n",
      "Inst: 14016 | Acc: 99.64% | Kappa: 0.79 | Drifts: 9\n",
      "Inst: 16000 | Acc: 99.63% | Kappa: 0.80 | Drifts: 9\n",
      "Inst: 18016 | Acc: 99.64% | Kappa: 0.80 | Drifts: 9\n",
      "Inst: 20000 | Acc: 99.66% | Kappa: 0.81 | Drifts: 9\n",
      "Inst: 22016 | Acc: 99.65% | Kappa: 0.81 | Drifts: 17\n",
      "Inst: 24000 | Acc: 99.67% | Kappa: 0.82 | Drifts: 18\n",
      "Inst: 26016 | Acc: 99.66% | Kappa: 0.81 | Drifts: 18\n",
      "Inst: 28000 | Acc: 99.67% | Kappa: 0.82 | Drifts: 18\n",
      "Inst: 30016 | Acc: 99.68% | Kappa: 0.82 | Drifts: 19\n",
      "Inst: 32000 | Acc: 99.69% | Kappa: 0.83 | Drifts: 21\n",
      "Inst: 34016 | Acc: 99.69% | Kappa: 0.84 | Drifts: 21\n",
      "Inst: 36000 | Acc: 99.70% | Kappa: 0.84 | Drifts: 22\n",
      "Inst: 38016 | Acc: 99.70% | Kappa: 0.84 | Drifts: 23\n",
      "Inst: 40000 | Acc: 99.70% | Kappa: 0.84 | Drifts: 23\n",
      "Inst: 42016 | Acc: 99.71% | Kappa: 0.85 | Drifts: 30\n",
      "Inst: 44000 | Acc: 99.72% | Kappa: 0.85 | Drifts: 30\n",
      "Inst: 46016 | Acc: 99.73% | Kappa: 0.85 | Drifts: 30\n",
      "Inst: 48000 | Acc: 99.74% | Kappa: 0.86 | Drifts: 31\n",
      "Inst: 50016 | Acc: 99.74% | Kappa: 0.86 | Drifts: 31\n",
      "Inst: 52000 | Acc: 99.74% | Kappa: 0.86 | Drifts: 31\n",
      "Inst: 54016 | Acc: 99.74% | Kappa: 0.86 | Drifts: 36\n",
      "Inst: 56000 | Acc: 99.74% | Kappa: 0.86 | Drifts: 36\n",
      "Inst: 58016 | Acc: 99.75% | Kappa: 0.86 | Drifts: 37\n",
      "Inst: 60000 | Acc: 99.75% | Kappa: 0.86 | Drifts: 38\n",
      "Inst: 62016 | Acc: 99.75% | Kappa: 0.87 | Drifts: 38\n",
      "Inst: 64000 | Acc: 99.76% | Kappa: 0.87 | Drifts: 42\n",
      "Inst: 66016 | Acc: 99.76% | Kappa: 0.87 | Drifts: 44\n",
      "Inst: 68000 | Acc: 99.76% | Kappa: 0.87 | Drifts: 48\n",
      "Inst: 70016 | Acc: 99.77% | Kappa: 0.87 | Drifts: 49\n",
      "Inst: 72000 | Acc: 99.77% | Kappa: 0.87 | Drifts: 49\n",
      "Inst: 74016 | Acc: 99.78% | Kappa: 0.88 | Drifts: 49\n",
      "Inst: 76000 | Acc: 99.78% | Kappa: 0.88 | Drifts: 51\n",
      "Inst: 78016 | Acc: 99.78% | Kappa: 0.88 | Drifts: 51\n",
      "Inst: 80000 | Acc: 99.78% | Kappa: 0.88 | Drifts: 56\n",
      "Inst: 82016 | Acc: 99.78% | Kappa: 0.88 | Drifts: 56\n",
      "Inst: 84000 | Acc: 99.78% | Kappa: 0.88 | Drifts: 56\n",
      "Inst: 86016 | Acc: 99.78% | Kappa: 0.88 | Drifts: 56\n",
      "Inst: 88000 | Acc: 99.78% | Kappa: 0.88 | Drifts: 56\n",
      "Inst: 90016 | Acc: 99.79% | Kappa: 0.88 | Drifts: 56\n",
      "Inst: 92000 | Acc: 99.79% | Kappa: 0.89 | Drifts: 61\n",
      "Inst: 94016 | Acc: 99.79% | Kappa: 0.89 | Drifts: 63\n",
      "Inst: 96000 | Acc: 99.79% | Kappa: 0.89 | Drifts: 64\n",
      "Inst: 98016 | Acc: 99.79% | Kappa: 0.89 | Drifts: 64\n",
      "Inst: 100000 | Acc: 99.79% | Kappa: 0.89 | Drifts: 64\n",
      "Alcançado o limite de 100000 instâncias. Finalizando...\n",
      "\n",
      "# Executando: sea | IR: 0.1 | Lambda: 10 | Seed: 123456789\n",
      "Aplicando Static Imbalance Ratio: 10.0%\n",
      "Executando: SEA | Tipo: static_ir | Seed: 123456789 | N_Feat: 3\n",
      "Inst: 2016 | Acc: 98.61% | Kappa: 0.92 | Drifts: 0\n",
      "Inst: 4000 | Acc: 98.92% | Kappa: 0.94 | Drifts: 0\n",
      "Inst: 6016 | Acc: 99.15% | Kappa: 0.95 | Drifts: 0\n",
      "Inst: 8000 | Acc: 99.28% | Kappa: 0.96 | Drifts: 0\n",
      "Inst: 10016 | Acc: 99.33% | Kappa: 0.96 | Drifts: 19\n",
      "Inst: 12000 | Acc: 99.31% | Kappa: 0.96 | Drifts: 29\n",
      "Inst: 14016 | Acc: 99.27% | Kappa: 0.96 | Drifts: 39\n",
      "Inst: 16000 | Acc: 99.28% | Kappa: 0.96 | Drifts: 49\n",
      "Inst: 18016 | Acc: 99.25% | Kappa: 0.96 | Drifts: 68\n",
      "Inst: 20000 | Acc: 99.28% | Kappa: 0.96 | Drifts: 78\n",
      "Inst: 22016 | Acc: 99.26% | Kappa: 0.96 | Drifts: 88\n",
      "Inst: 24000 | Acc: 99.29% | Kappa: 0.96 | Drifts: 88\n",
      "Inst: 26016 | Acc: 99.30% | Kappa: 0.96 | Drifts: 98\n",
      "Inst: 28000 | Acc: 99.32% | Kappa: 0.96 | Drifts: 107\n",
      "Inst: 30016 | Acc: 99.28% | Kappa: 0.96 | Drifts: 107\n",
      "Inst: 32000 | Acc: 99.30% | Kappa: 0.96 | Drifts: 117\n",
      "Inst: 34016 | Acc: 99.28% | Kappa: 0.96 | Drifts: 117\n",
      "Inst: 36000 | Acc: 99.29% | Kappa: 0.96 | Drifts: 117\n",
      "Inst: 38016 | Acc: 99.28% | Kappa: 0.96 | Drifts: 117\n",
      "Inst: 40000 | Acc: 99.30% | Kappa: 0.96 | Drifts: 117\n",
      "Inst: 42016 | Acc: 99.32% | Kappa: 0.96 | Drifts: 117\n",
      "Inst: 44000 | Acc: 99.32% | Kappa: 0.96 | Drifts: 127\n",
      "Inst: 46016 | Acc: 99.24% | Kappa: 0.96 | Drifts: 147\n",
      "Inst: 48000 | Acc: 99.23% | Kappa: 0.96 | Drifts: 147\n",
      "Inst: 50016 | Acc: 99.19% | Kappa: 0.96 | Drifts: 157\n",
      "Inst: 52000 | Acc: 99.13% | Kappa: 0.95 | Drifts: 157\n",
      "Inst: 54016 | Acc: 99.12% | Kappa: 0.95 | Drifts: 167\n",
      "Inst: 56000 | Acc: 99.08% | Kappa: 0.95 | Drifts: 177\n",
      "Inst: 58016 | Acc: 99.06% | Kappa: 0.95 | Drifts: 207\n",
      "Inst: 60000 | Acc: 99.05% | Kappa: 0.95 | Drifts: 207\n",
      "Inst: 62016 | Acc: 99.02% | Kappa: 0.95 | Drifts: 217\n",
      "Inst: 64000 | Acc: 99.03% | Kappa: 0.95 | Drifts: 217\n",
      "Inst: 66016 | Acc: 99.02% | Kappa: 0.95 | Drifts: 237\n",
      "Inst: 68000 | Acc: 99.00% | Kappa: 0.94 | Drifts: 247\n",
      "Inst: 70016 | Acc: 98.98% | Kappa: 0.94 | Drifts: 267\n",
      "Inst: 72000 | Acc: 98.98% | Kappa: 0.94 | Drifts: 267\n",
      "Inst: 74016 | Acc: 98.99% | Kappa: 0.94 | Drifts: 267\n",
      "Inst: 76000 | Acc: 98.99% | Kappa: 0.94 | Drifts: 267\n",
      "Inst: 78016 | Acc: 99.00% | Kappa: 0.94 | Drifts: 277\n",
      "Inst: 80000 | Acc: 98.99% | Kappa: 0.94 | Drifts: 277\n",
      "Inst: 82016 | Acc: 99.01% | Kappa: 0.95 | Drifts: 277\n",
      "Inst: 84000 | Acc: 99.00% | Kappa: 0.94 | Drifts: 287\n",
      "Inst: 86016 | Acc: 98.99% | Kappa: 0.94 | Drifts: 307\n",
      "Inst: 88000 | Acc: 99.00% | Kappa: 0.94 | Drifts: 307\n",
      "Inst: 90016 | Acc: 98.99% | Kappa: 0.94 | Drifts: 327\n",
      "Inst: 92000 | Acc: 98.99% | Kappa: 0.94 | Drifts: 337\n",
      "Inst: 94016 | Acc: 98.99% | Kappa: 0.94 | Drifts: 337\n",
      "Inst: 96000 | Acc: 99.01% | Kappa: 0.95 | Drifts: 337\n",
      "Inst: 98016 | Acc: 99.00% | Kappa: 0.95 | Drifts: 357\n",
      "Inst: 100000 | Acc: 99.00% | Kappa: 0.94 | Drifts: 357\n",
      "Alcançado o limite de 100000 instâncias. Finalizando...\n",
      "\n",
      "# Executando: sea | IR: 0.01 | Lambda: 10 | Seed: 123456789\n",
      "Aplicando Static Imbalance Ratio: 1.0%\n",
      "Executando: SEA | Tipo: static_ir | Seed: 123456789 | N_Feat: 3\n",
      "Inst: 2016 | Acc: 99.11% | Kappa: 0.47 | Drifts: 0\n",
      "Inst: 4000 | Acc: 99.38% | Kappa: 0.59 | Drifts: 0\n",
      "Inst: 6016 | Acc: 99.48% | Kappa: 0.69 | Drifts: 0\n",
      "Inst: 8000 | Acc: 99.52% | Kappa: 0.69 | Drifts: 0\n",
      "Inst: 10016 | Acc: 99.54% | Kappa: 0.71 | Drifts: 0\n",
      "Inst: 12000 | Acc: 99.59% | Kappa: 0.75 | Drifts: 10\n",
      "Inst: 14016 | Acc: 99.61% | Kappa: 0.78 | Drifts: 10\n",
      "Inst: 16000 | Acc: 99.62% | Kappa: 0.79 | Drifts: 10\n",
      "Inst: 18016 | Acc: 99.62% | Kappa: 0.78 | Drifts: 10\n",
      "Inst: 20000 | Acc: 99.64% | Kappa: 0.80 | Drifts: 10\n",
      "Inst: 22016 | Acc: 99.63% | Kappa: 0.79 | Drifts: 20\n",
      "Inst: 24000 | Acc: 99.65% | Kappa: 0.80 | Drifts: 20\n",
      "Inst: 26016 | Acc: 99.63% | Kappa: 0.79 | Drifts: 20\n",
      "Inst: 28000 | Acc: 99.62% | Kappa: 0.78 | Drifts: 20\n",
      "Inst: 30016 | Acc: 99.61% | Kappa: 0.77 | Drifts: 20\n",
      "Inst: 32000 | Acc: 99.61% | Kappa: 0.78 | Drifts: 20\n",
      "Inst: 34016 | Acc: 99.61% | Kappa: 0.78 | Drifts: 20\n",
      "Inst: 36000 | Acc: 99.61% | Kappa: 0.78 | Drifts: 20\n",
      "Inst: 38016 | Acc: 99.60% | Kappa: 0.78 | Drifts: 20\n",
      "Inst: 40000 | Acc: 99.60% | Kappa: 0.78 | Drifts: 20\n",
      "Inst: 42016 | Acc: 99.61% | Kappa: 0.78 | Drifts: 29\n",
      "Inst: 44000 | Acc: 99.62% | Kappa: 0.78 | Drifts: 29\n",
      "Inst: 46016 | Acc: 99.63% | Kappa: 0.78 | Drifts: 29\n",
      "Inst: 48000 | Acc: 99.64% | Kappa: 0.79 | Drifts: 29\n",
      "Inst: 50016 | Acc: 99.64% | Kappa: 0.80 | Drifts: 29\n",
      "Inst: 52000 | Acc: 99.65% | Kappa: 0.80 | Drifts: 29\n",
      "Inst: 54016 | Acc: 99.65% | Kappa: 0.80 | Drifts: 39\n",
      "Inst: 56000 | Acc: 99.66% | Kappa: 0.80 | Drifts: 39\n",
      "Inst: 58016 | Acc: 99.67% | Kappa: 0.81 | Drifts: 39\n",
      "Inst: 60000 | Acc: 99.67% | Kappa: 0.81 | Drifts: 39\n",
      "Inst: 62016 | Acc: 99.68% | Kappa: 0.82 | Drifts: 39\n",
      "Inst: 64000 | Acc: 99.68% | Kappa: 0.82 | Drifts: 49\n",
      "Inst: 66016 | Acc: 99.69% | Kappa: 0.82 | Drifts: 49\n",
      "Inst: 68000 | Acc: 99.69% | Kappa: 0.83 | Drifts: 59\n",
      "Inst: 70016 | Acc: 99.69% | Kappa: 0.83 | Drifts: 59\n",
      "Inst: 72000 | Acc: 99.70% | Kappa: 0.83 | Drifts: 59\n",
      "Inst: 74016 | Acc: 99.70% | Kappa: 0.83 | Drifts: 59\n",
      "Inst: 76000 | Acc: 99.70% | Kappa: 0.84 | Drifts: 59\n",
      "Inst: 78016 | Acc: 99.71% | Kappa: 0.84 | Drifts: 59\n",
      "Inst: 80000 | Acc: 99.72% | Kappa: 0.84 | Drifts: 68\n",
      "Inst: 82016 | Acc: 99.72% | Kappa: 0.84 | Drifts: 68\n",
      "Inst: 84000 | Acc: 99.71% | Kappa: 0.84 | Drifts: 68\n",
      "Inst: 86016 | Acc: 99.71% | Kappa: 0.84 | Drifts: 68\n",
      "Inst: 88000 | Acc: 99.72% | Kappa: 0.84 | Drifts: 68\n",
      "Inst: 90016 | Acc: 99.73% | Kappa: 0.85 | Drifts: 68\n",
      "Inst: 92000 | Acc: 99.73% | Kappa: 0.85 | Drifts: 77\n",
      "Inst: 94016 | Acc: 99.73% | Kappa: 0.85 | Drifts: 77\n",
      "Inst: 96000 | Acc: 99.73% | Kappa: 0.85 | Drifts: 77\n",
      "Inst: 98016 | Acc: 99.73% | Kappa: 0.85 | Drifts: 77\n",
      "Inst: 100000 | Acc: 99.74% | Kappa: 0.85 | Drifts: 77\n",
      "Alcançado o limite de 100000 instâncias. Finalizando...\n",
      "\n",
      "# Executando Dataset Real: Elec2\n",
      "Executando: ELEC2 | Tipo: binary | Seed: 123456789 | N_Feat: 17\n",
      "Inst: 2016 | Acc: 91.62% | Kappa: 0.83 | Drifts: 49\n",
      "Inst: 4000 | Acc: 93.05% | Kappa: 0.85 | Drifts: 81\n",
      "Inst: 6016 | Acc: 92.59% | Kappa: 0.84 | Drifts: 118\n",
      "Inst: 8000 | Acc: 92.19% | Kappa: 0.84 | Drifts: 157\n",
      "Inst: 10016 | Acc: 92.79% | Kappa: 0.85 | Drifts: 187\n",
      "Inst: 12000 | Acc: 92.62% | Kappa: 0.85 | Drifts: 233\n",
      "Inst: 14016 | Acc: 92.25% | Kappa: 0.84 | Drifts: 242\n",
      "Inst: 16000 | Acc: 91.92% | Kappa: 0.84 | Drifts: 269\n",
      "Inst: 18016 | Acc: 91.46% | Kappa: 0.83 | Drifts: 298\n",
      "Inst: 20000 | Acc: 91.47% | Kappa: 0.83 | Drifts: 323\n",
      "Inst: 22016 | Acc: 91.03% | Kappa: 0.82 | Drifts: 374\n",
      "Inst: 24000 | Acc: 90.60% | Kappa: 0.81 | Drifts: 442\n",
      "Inst: 26016 | Acc: 90.57% | Kappa: 0.81 | Drifts: 469\n",
      "Inst: 28000 | Acc: 90.55% | Kappa: 0.81 | Drifts: 511\n",
      "Inst: 30016 | Acc: 90.38% | Kappa: 0.80 | Drifts: 525\n",
      "Inst: 32000 | Acc: 90.05% | Kappa: 0.80 | Drifts: 544\n",
      "Inst: 34016 | Acc: 89.82% | Kappa: 0.79 | Drifts: 568\n",
      "Inst: 36000 | Acc: 89.74% | Kappa: 0.79 | Drifts: 578\n",
      "Inst: 38016 | Acc: 89.73% | Kappa: 0.79 | Drifts: 590\n",
      "Inst: 40000 | Acc: 89.77% | Kappa: 0.79 | Drifts: 608\n",
      "Inst: 42016 | Acc: 89.87% | Kappa: 0.79 | Drifts: 625\n",
      "Inst: 44000 | Acc: 89.79% | Kappa: 0.79 | Drifts: 648\n",
      "Executando: ELEC2 | Tipo: binary | Seed: 123456789 | N_Feat: 17\n",
      "Inst: 2016 | Acc: 91.32% | Kappa: 0.82 | Drifts: 49\n",
      "Inst: 4000 | Acc: 92.45% | Kappa: 0.84 | Drifts: 79\n",
      "Inst: 6016 | Acc: 92.22% | Kappa: 0.84 | Drifts: 119\n",
      "Inst: 8000 | Acc: 92.05% | Kappa: 0.84 | Drifts: 159\n",
      "Inst: 10016 | Acc: 92.45% | Kappa: 0.85 | Drifts: 189\n",
      "Inst: 12000 | Acc: 92.20% | Kappa: 0.84 | Drifts: 240\n",
      "Inst: 14016 | Acc: 91.68% | Kappa: 0.83 | Drifts: 260\n",
      "Inst: 16000 | Acc: 91.40% | Kappa: 0.83 | Drifts: 275\n",
      "Inst: 18016 | Acc: 90.96% | Kappa: 0.82 | Drifts: 319\n",
      "Inst: 20000 | Acc: 90.94% | Kappa: 0.82 | Drifts: 339\n",
      "Inst: 22016 | Acc: 90.07% | Kappa: 0.80 | Drifts: 416\n",
      "Inst: 24000 | Acc: 89.68% | Kappa: 0.79 | Drifts: 495\n",
      "Inst: 26016 | Acc: 89.70% | Kappa: 0.79 | Drifts: 515\n",
      "Inst: 28000 | Acc: 89.74% | Kappa: 0.79 | Drifts: 555\n",
      "Inst: 30016 | Acc: 89.60% | Kappa: 0.79 | Drifts: 565\n",
      "Inst: 32000 | Acc: 89.32% | Kappa: 0.78 | Drifts: 575\n",
      "Inst: 34016 | Acc: 89.16% | Kappa: 0.78 | Drifts: 579\n",
      "Inst: 36000 | Acc: 89.08% | Kappa: 0.78 | Drifts: 581\n",
      "Inst: 38016 | Acc: 89.05% | Kappa: 0.77 | Drifts: 599\n",
      "Inst: 40000 | Acc: 89.03% | Kappa: 0.77 | Drifts: 603\n",
      "Inst: 42016 | Acc: 89.11% | Kappa: 0.78 | Drifts: 623\n",
      "Inst: 44000 | Acc: 89.04% | Kappa: 0.78 | Drifts: 663\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Verifica se estamos no Jupyter ou Terminal\n",
    "    # O Jupyter geralmente tem 'ipykernel_launcher' ou '-f' nos argumentos\n",
    "    is_jupyter = any('ipykernel' in arg or '-f' in arg for arg in sys.argv)\n",
    "    \n",
    "    # Se rodado via linha de comando\n",
    "    if not is_jupyter and len(sys.argv) > 1:\n",
    "        parser = argparse.ArgumentParser()\n",
    "        parser.add_argument('--dataset', type=str, default='elec2')\n",
    "        parser.add_argument('--ir', type=float, default=None)\n",
    "        parser.add_argument('--seed', type=int, default=123456789)\n",
    "        parser.add_argument('--exp_type', type=str, default='binary')\n",
    "        parser.add_argument('--n_models', type=int, default=30)\n",
    "        parser.add_argument('--n_classes', type=int, default=2)\n",
    "        parser.add_argument('--batch_size', type=int, default=32)\n",
    "        parser.add_argument('--n_instances', type=int, default=100000)\n",
    "        parser.add_argument('--lambda_val', type=int, default=6)\n",
    "        args = parser.parse_args()\n",
    "        \n",
    "        main(\n",
    "            dataset=args.dataset, ir=args.ir, seed=args.seed,\n",
    "            exp_type=args.exp_type, n_models=args.n_models,\n",
    "            n_classes=args.n_classes, batch_size=args.batch_size,\n",
    "            n_instances=args.n_instances, lambda_val=args.lambda_val\n",
    "        )\n",
    "    else:\n",
    "        # Execução via Notebook (parâmetros manuais abaixo)\n",
    "        print(\"Ambiente Notebook detectado. Usando parâmetros padrão...\")\n",
    "        # main(dataset='agrawal', ir=0.1, seed=123456789, exp_type='static_ir')\n",
    "        # main(dataset='agrawal', ir=0.01, seed=123456789, exp_type='static_ir')\n",
    "        # main(\n",
    "        #     dataset='elec2', \n",
    "        #     seed=123456789, \n",
    "        #     exp_type='binary', \n",
    "        #     batch_size=32,\n",
    "        #     n_models=30, n_classes=2\n",
    "        # )\n",
    "        # Exemplo de execução para os dois principais geradores do Survey\n",
    "        # run_static_imbalance_suite(\n",
    "        #     datasets_list=['agrawal', 'sea', 'randomtree'], \n",
    "        #     seeds=[123456789], \n",
    "        #     ir_list=[0.1, 0.05, 0.01]\n",
    "        # )\n",
    "        run_full_experiment_suite()\n",
    "        \n",
    "        # main(dataset='elec2', seed=123456789, exp_type='binary', batch_size=32, n_models=30, n_classes=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e21db2a8-2a6b-4b76-b1d1-7cc7061956fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
