{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9fb43fba-30f3-4d35-be79-e992d8d599fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import numpy as np\n",
    "import statistics\n",
    "from river import base, tree, drift, utils, stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d6bb1736-1eed-4f00-9c17-63c9bb25773d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ARTE(base.Ensemble, base.Classifier):\n",
    "    \"\"\"Adaptive Random Tree Ensemble (ARTE) portado do MOA.\n",
    "    \n",
    "    Algoritmo adaptativo para fluxos de dados evolutivos de Paim e Enembreck.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        model: base.Classifier = None,\n",
    "        n_models: int = 100,\n",
    "        lambd: float = 6.0,\n",
    "        drift_detector: base.DriftDetector = None,\n",
    "        window_size: int = 1000,\n",
    "        n_rejections: int = 5,\n",
    "        seed: int = 1\n",
    "    ):\n",
    "        # O modelo base sugerido no original é a ARFHoeffdingTree\n",
    "        # No River, usamos HoeffdingTreeClassifier como base\n",
    "        self.model = model or tree.HoeffdingTreeClassifier()\n",
    "        self.n_models = n_models\n",
    "        self.lambd = lambd\n",
    "        self.drift_detector = drift_detector or drift.ADWIN(delta=1e-3)\n",
    "        self.window_size = window_size\n",
    "        self.n_rejections = n_rejections\n",
    "        self.seed = seed\n",
    "        self._rng = np.random.RandomState(self.seed)\n",
    "        \n",
    "        # Inicialização dos membros conforme a estrutura AREBaseLearner do original\n",
    "        self._ensemble_members = []\n",
    "        for i in range(self.n_models):\n",
    "            m = {\n",
    "                'model': self.model.clone(),\n",
    "                'detector': self.drift_detector.clone(),\n",
    "                'untrained_counts': collections.defaultdict(int),\n",
    "                'window_acc': utils.Rolling(stats.Mean(), window_size=self.window_size),\n",
    "                'instances_trained': 0\n",
    "            }\n",
    "            self._ensemble_members.append(m)\n",
    "            \n",
    "        super().__init__(models=[m['model'] for m in self._ensemble_members])\n",
    "        self._avg_window_acc = 0.0\n",
    "\n",
    "    def learn_one(self, x, y):\n",
    "        all_accs = []\n",
    "        \n",
    "        for m in self._ensemble_members:\n",
    "            # Predição para controle de erro e lógica de rejeição\n",
    "            y_pred = m['model'].predict_one(x)\n",
    "            correct = (y == y_pred)\n",
    "            \n",
    "            # Estratégia de Regularização Adaptativa:\n",
    "            # Para evitar que domínios com ruído dominem, treina no erro\n",
    "            # ou após N rejeições (acertos)\n",
    "            will_train = not correct\n",
    "            \n",
    "            if correct:\n",
    "                m['untrained_counts'][y] += 1\n",
    "                if self.n_rejections > 0 and m['untrained_counts'][y] >= self.n_rejections:\n",
    "                    m['untrained_counts'][y] = 0\n",
    "                    will_train = True\n",
    "            \n",
    "            if will_train:\n",
    "                # Online Bagging via Poisson\n",
    "                k = self._rng.poisson(self.lambd)\n",
    "                if k > 0:\n",
    "                    for _ in range(k):\n",
    "                        m['model'].learn_one(x, y)\n",
    "                        m['instances_trained'] += 1\n",
    "            \n",
    "            # Detecção de Drift individual\n",
    "            m['detector'].update(0 if correct else 1)\n",
    "            if m['detector'].drift_detected:\n",
    "                self._reset_member(m)\n",
    "            \n",
    "            # Atualiza estatísticas da janela deslizante\n",
    "            m['window_acc'].update(1 if correct else 0)\n",
    "            all_accs.append(m['window_acc'].get())\n",
    "\n",
    "        # Atualiza média global para critério de votação seletiva\n",
    "        if all_accs:\n",
    "            self._avg_window_acc = statistics.mean(all_accs)\n",
    "            \n",
    "        return self\n",
    "\n",
    "    def predict_proba_one(self, x):\n",
    "        combined_votes = collections.Counter()\n",
    "        \n",
    "        # O ARTE filtra votantes cuja acurácia na janela é inferior à média global\n",
    "        eligible_members = [\n",
    "            m for m in self._ensemble_members \n",
    "            if self.window_size == 0 or m['window_acc'].get() >= self._avg_window_acc\n",
    "        ]\n",
    "        \n",
    "        # Fallback se ninguém estiver acima da média (ex: início do stream)\n",
    "        if not eligible_members:\n",
    "            eligible_members = self._ensemble_members\n",
    "\n",
    "        for m in eligible_members:\n",
    "            votes = m['model'].predict_proba_one(x)\n",
    "            if votes:\n",
    "                total = sum(votes.values())\n",
    "                if total > 0:\n",
    "                    for cls, prob in votes.items():\n",
    "                        combined_votes[cls] += prob / total\n",
    "\n",
    "        return combined_votes\n",
    "\n",
    "    def _reset_member(self, m):\n",
    "        \"\"\"Reinicia o modelo e estatísticas após detecção de mudança.\"\"\"\n",
    "        m['model'] = self.model.clone()\n",
    "        m['detector'] = self.drift_detector.clone()\n",
    "        m['untrained_counts'].clear()\n",
    "        m['window_acc'] = utils.Rolling(stats.Mean(), window_size=self.window_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4170ac8f-6a90-4ed7-9776-63bd1cb492ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando Teste com ARTE no dataset: ElecNorm\n",
      "Configuração: 100 árvores, g=100, delta=0.01, 5 Seeds\n",
      "Gravando em: resultados_arte_test.csv\n",
      "\n",
      "\n",
      ">>> Seed 1 em execução...\n",
      "Instâncias   | Acurácia   | Tempo (s)  | Memória (MB)\n",
      "-------------------------------------------------------\n",
      "5000         |    94.02% |     55.70 |       329.91\n",
      "10000        |    93.41% |    115.67 |       424.91\n",
      "15000        |    93.47% |    175.29 |       424.91\n",
      "20000        |    93.33% |    240.85 |       433.53\n",
      "25000        |    92.64% |    313.92 |       447.03\n",
      "30000        |    92.40% |    385.70 |       447.03\n",
      "35000        |    92.20% |    461.71 |       447.03\n",
      "40000        |    92.08% |    533.70 |       447.03\n",
      "45000        |    92.14% |    604.28 |       447.03\n",
      "-------------------------------------------------------\n",
      "RESULTADO SEED 1: 92.15%\n",
      "\n",
      ">>> Seed 2 em execução...\n",
      "Instâncias   | Acurácia   | Tempo (s)  | Memória (MB)\n",
      "-------------------------------------------------------\n",
      "5000         |    94.04% |     58.13 |       438.48\n",
      "10000        |    93.48% |    122.02 |       438.61\n",
      "15000        |    93.47% |    185.18 |       441.48\n",
      "20000        |    93.41% |    253.44 |       460.61\n",
      "25000        |    92.73% |    327.92 |       473.36\n",
      "30000        |    92.52% |    400.52 |       470.99\n",
      "35000        |    92.32% |    477.72 |       470.99\n",
      "40000        |    92.20% |    551.86 |       470.99\n",
      "45000        |    92.22% |    623.55 |       470.99\n",
      "-------------------------------------------------------\n",
      "RESULTADO SEED 2: 92.24%\n",
      "\n",
      ">>> Seed 3 em execução...\n",
      "Instâncias   | Acurácia   | Tempo (s)  | Memória (MB)\n",
      "-------------------------------------------------------\n",
      "5000         |    94.08% |     59.80 |       457.94\n",
      "10000        |    93.50% |    123.65 |       457.94\n",
      "15000        |    93.58% |    184.10 |       457.94\n",
      "20000        |    93.39% |    250.43 |       457.94\n",
      "25000        |    92.70% |    323.85 |       463.56\n",
      "30000        |    92.44% |    398.52 |       463.56\n",
      "35000        |    92.29% |    476.90 |       463.56\n",
      "40000        |    92.16% |    550.19 |       463.56\n",
      "45000        |    92.22% |    621.18 |       465.19\n",
      "-------------------------------------------------------\n",
      "RESULTADO SEED 3: 92.24%\n",
      "\n",
      ">>> Seed 4 em execução...\n",
      "Instâncias   | Acurácia   | Tempo (s)  | Memória (MB)\n",
      "-------------------------------------------------------\n",
      "5000         |    94.02% |     58.14 |       465.19\n",
      "10000        |    93.51% |    121.25 |       465.19\n",
      "15000        |    93.57% |    182.57 |       465.19\n",
      "20000        |    93.39% |    249.20 |       465.19\n",
      "25000        |    92.66% |    325.13 |       471.94\n",
      "30000        |    92.46% |    398.48 |       471.94\n",
      "35000        |    92.21% |    475.22 |       471.94\n",
      "40000        |    92.11% |    547.79 |       471.94\n",
      "45000        |    92.17% |    617.77 |       471.94\n",
      "-------------------------------------------------------\n",
      "RESULTADO SEED 4: 92.19%\n",
      "\n",
      ">>> Seed 5 em execução...\n",
      "Instâncias   | Acurácia   | Tempo (s)  | Memória (MB)\n",
      "-------------------------------------------------------\n",
      "5000         |    94.04% |     59.08 |       463.54\n",
      "10000        |    93.50% |    122.08 |       463.54\n",
      "15000        |    93.54% |    184.65 |       463.54\n",
      "20000        |    93.41% |    252.12 |       463.54\n",
      "25000        |    92.73% |    333.29 |       466.04\n",
      "30000        |    92.54% |    415.36 |       466.04\n",
      "35000        |    92.34% |    499.99 |       466.04\n",
      "40000        |    92.25% |    580.16 |       466.04\n",
      "45000        |    92.26% |    652.90 |       466.04\n",
      "-------------------------------------------------------\n",
      "RESULTADO SEED 5: 92.28%\n",
      "\n",
      "=======================================================\n",
      "TESTE CONCLUÍDO. Resultados disponíveis em resultados_arte_test.csv\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import os\n",
    "import psutil\n",
    "import csv\n",
    "import statistics\n",
    "import numpy as np\n",
    "from river import metrics, tree, drift, stream\n",
    "\n",
    "def get_memory_usage():\n",
    "    \"\"\"Retorna o uso de memória RAM física (RSS) em MB.\"\"\"\n",
    "    process = psutil.Process(os.getpid())\n",
    "    return process.memory_info().rss / (1024 * 1024)\n",
    "\n",
    "# 1. Configurações da base de teste\n",
    "base_path = os.path.expanduser(\"~/moa/aldopaim/AdaptiveRegularizedEnsemble/datasets\")\n",
    "dataset_name = \"ElecNorm\"\n",
    "filename = \"elecNormNew.arff\"\n",
    "target_column = \"class\"  # Já identificado anteriormente para esta base\n",
    "output_file = \"resultados_arte_test.csv\"\n",
    "\n",
    "# 2. Inicialização do arquivo CSV\n",
    "header = ['Dataset', 'Seed', 'Acuracia', 'Tempo_s', 'Memoria_MB', 'Instancias']\n",
    "with open(output_file, 'w', newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(header)\n",
    "\n",
    "print(f\"Iniciando Teste com ARTE no dataset: {dataset_name}\")\n",
    "print(f\"Configuração: 100 árvores, g=100, delta=0.01, 5 Seeds\")\n",
    "print(f\"Gravando em: {output_file}\\n\")\n",
    "\n",
    "# 3. Loop de Experimentação (5 Seeds)\n",
    "for s in range(1, 6):\n",
    "    print(f\"\\n>>> Seed {s} em execução...\")\n",
    "    print(f\"{'Instâncias':<12} | {'Acurácia':<10} | {'Tempo (s)':<10} | {'Memória (MB)':<12}\")\n",
    "    print(\"-\" * 55)\n",
    "\n",
    "    # Hiperparâmetros recomendados pelo autor\n",
    "    base_tree = tree.HoeffdingTreeClassifier(grace_period=100, delta=0.01)\n",
    "    adwin_detector = drift.ADWIN(delta=1e-3)\n",
    "    \n",
    "    # Instanciação do ARTE portado\n",
    "    model = ARTE(\n",
    "        model=base_tree,\n",
    "        n_models=100,\n",
    "        drift_detector=adwin_detector,\n",
    "        seed=s\n",
    "    )\n",
    "    metric = metrics.Accuracy()\n",
    "    \n",
    "    start_time = time.perf_counter()\n",
    "    count = 0\n",
    "    file_path = os.path.join(base_path, filename)\n",
    "    \n",
    "    try:\n",
    "        # Carregamento via stream preguiçosa\n",
    "        dataset_stream = stream.iter_arff(file_path, target=target_column)\n",
    "        \n",
    "        for x, y in dataset_stream:\n",
    "            # Test-then-Train\n",
    "            y_pred = model.predict_one(x)\n",
    "            if y_pred is not None:\n",
    "                metric.update(y, y_pred)\n",
    "            \n",
    "            model.learn_one(x, y)\n",
    "            count += 1\n",
    "            \n",
    "            # Print intermediário a cada 5.000 instâncias para ElecNormNew\n",
    "            if count % 5000 == 0:\n",
    "                elapsed = time.perf_counter() - start_time\n",
    "                mem = get_memory_usage()\n",
    "                print(f\"{count:<12} | {metric.get():>9.2%} | {elapsed:>9.2f} | {mem:>12.2f}\")\n",
    "\n",
    "        # Finalização da Rodada\n",
    "        total_elapsed = time.perf_counter() - start_time\n",
    "        final_mem = get_memory_usage()\n",
    "        final_acc = metric.get()\n",
    "        \n",
    "        print(\"-\" * 55)\n",
    "        print(f\"RESULTADO SEED {s}: {final_acc:.2%}\")\n",
    "\n",
    "        # Salvamento Persistente\n",
    "        with open(output_file, 'a', newline='') as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow([dataset_name, s, f\"{final_acc:.4f}\", f\"{total_elapsed:.2f}\", f\"{final_mem:.2f}\", count])\n",
    "            f.flush() # Força a gravação física no disco\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Falha ao processar Seed {s}: {e}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*55)\n",
    "print(f\"TESTE CONCLUÍDO. Resultados disponíveis em {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c2c776a-1d66-4607-b90d-427179eea114",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_target_column_name(file_path):\n",
    "    \"\"\"Detecta dinamicamente o nome da última coluna (target) no ARFF.\"\"\"\n",
    "    last_attribute = None\n",
    "    with open(file_path, 'r') as f:\n",
    "        for line in f:\n",
    "            line_upper = line.upper().strip()\n",
    "            if line_upper.startswith('@ATTRIBUTE'):\n",
    "                parts = line.split()\n",
    "                if len(parts) > 1:\n",
    "                    last_attribute = parts[1].replace(\"'\", \"\").replace('\"', '')\n",
    "            if line_upper.startswith('@DATA'):\n",
    "                break\n",
    "    return last_attribute\n",
    "\n",
    "def get_memory_usage():\n",
    "    \"\"\"Retorna o uso de memória em MB.\"\"\"\n",
    "    process = psutil.Process(os.getpid())\n",
    "    return process.memory_info().rss / (1024 * 1024)\n",
    "\n",
    "# 1. Configuração de Caminhos e Datasets\n",
    "base_path = os.path.expanduser(\"~/moa/aldopaim/AdaptiveRegularizedEnsemble/datasets\")\n",
    "output_file = \"resultados_are_river.csv\"\n",
    "arff_files = {\n",
    "    \"Airlines\": \"airlines.arff\", \"Census\": \"census.arff\", \"Connect-4\": \"connect-4.arff\",\n",
    "    \"Covtype\": \"covtypeNorm.arff\", \"ElecNorm\": \"elecNormNew.arff\", \"GMSC\": \"GMSC.arff\",\n",
    "    \"Keystroke\": \"keystroke.arff\", \"NOAA\": \"NOAA.arff\", \"Nomao\": \"nomao.arff\",\n",
    "    \"Outdoor\": \"outdoor.arff\", \"Ozone\": \"ozone.arff\"\n",
    "}\n",
    "\n",
    "# 2. Preparação do arquivo CSV\n",
    "header = ['Dataset', 'Seed', 'Acuracia', 'Tempo_s', 'Memoria_MB', 'Instancias']\n",
    "with open(output_file, 'w', newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(header)\n",
    "\n",
    "# 3. Loop Principal: Datasets -> Seeds (1 a 5)\n",
    "print(f\"{'Dataset':<12} | {'Seed':<5} | {'Acurácia':<10} | {'Tempo (s)':<10}\")\n",
    "print(\"-\" * 45)\n",
    "\n",
    "for name, filename in arff_files.items():\n",
    "    file_path = os.path.join(base_path, filename)\n",
    "    if not os.path.exists(file_path): \n",
    "        print(f\"![AVISO] Arquivo {filename} não encontrado. Pulando base {name}.\")\n",
    "        continue\n",
    "\n",
    "    target_col = get_target_column_name(file_path)\n",
    "    \n",
    "    # Executa 5 rodadas com seeds diferentes\n",
    "    for s in range(1, 6):\n",
    "        print(f\"\\n>>> Base: {name} | Seed: {s} | Target: {target_col}\")\n",
    "        print(f\"{'Instâncias':<12} | {'Acurácia':<10} | {'Tempo (s)':<10} | {'Memória (MB)':<12}\")\n",
    "        print(\"-\" * 55)\n",
    "        \n",
    "        # Reinicia Hiperparâmetros para garantir independência entre as rodadas\n",
    "        base_tree = tree.HoeffdingTreeClassifier(grace_period=100, delta=0.01)\n",
    "        adwin_detector = drift.ADWIN(delta=1e-3)\n",
    "        \n",
    "        model = ARTE(\n",
    "            model=base_tree,\n",
    "            n_models=100,\n",
    "            drift_detector=adwin_detector,\n",
    "            seed=s\n",
    "        )\n",
    "        metric = metrics.Accuracy()\n",
    "        \n",
    "        start_time = time.perf_counter()\n",
    "        count = 0\n",
    "        \n",
    "        try:\n",
    "            dataset_stream = stream.iter_arff(file_path, target=target_col)\n",
    "            \n",
    "            for x, y in dataset_stream:\n",
    "                y_pred = model.predict_one(x)\n",
    "                if y_pred is not None:\n",
    "                    metric.update(y, y_pred)\n",
    "                model.learn_one(x, y)\n",
    "                count += 1\n",
    "\n",
    "                # Print intermediário a cada 10.000 instâncias para acompanhar evolução\n",
    "                if count % 10000 == 0:\n",
    "                    elapsed = time.perf_counter() - start_time\n",
    "                    mem = get_memory_usage()\n",
    "                    print(f\"{count:<12} | {metric.get():>9.2%} | {elapsed:>9.2f} | {mem:>12.2f}\")\n",
    "            \n",
    "            # Fim da rodada\n",
    "            total_elapsed = time.perf_counter() - start_time\n",
    "            final_mem = get_memory_usage()\n",
    "            final_acc = metric.get()\n",
    "\n",
    "            print(\"-\" * 55)\n",
    "            print(f\"CONCLUÍDO: {name} (Seed {s}) | Acc: {final_acc:.2%} | Tempo: {total_elapsed:.2f}s\")\n",
    "            \n",
    "            # Salva no CSV\n",
    "            with open(output_file, 'a', newline='') as f:\n",
    "                writer = csv.writer(f)\n",
    "                writer.writerow([name, s, f\"{final_acc:.4f}\", f\"{total_elapsed:.2f}\", f\"{final_mem:.2f}\", count])\n",
    "                f.flush() # Força a escrita no disco agora\n",
    "            \n",
    "            print(f\"{name:<12} | {s:<5} | {acc:>9.2%} | {elapsed:>9.2f}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Erro ao processar {name} na Seed {s}: {e}\")\n",
    "\n",
    "print(\"-\" * 45)\n",
    "print(f\"Experimento concluído! Resultados salvos em: {output_file}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
